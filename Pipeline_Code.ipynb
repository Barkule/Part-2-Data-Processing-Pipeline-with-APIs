{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qalkaMlhQqac",
        "outputId": "466c7b37-8113-4b4a-f668-628c1c80855a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.44.1\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers pydantic\n",
        "!pip install bitsandbytes\n",
        "!pip install pydantic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1GM6okDQTS-",
        "outputId": "4113fe85-38d5-4e6f-ab82-6778b12ab486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.23.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.4\n",
            "    Uninstalling openai-1.54.4:\n",
            "      Successfully uninstalled openai-1.54.4\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install openai transformers accelerate pydantic\n",
        "\n",
        "!pip install openai==0.28\n",
        "\n",
        "\n",
        "import openai\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from pydantic import BaseModel, ValidationError\n",
        "import json\n",
        "import torch\n",
        "from getpass import getpass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDmpLX1LQdB-"
      },
      "outputs": [],
      "source": [
        "#structure of expected JSON output using Pydantic\n",
        "class ProcessedData(BaseModel):\n",
        "    title: str\n",
        "    summary: str\n",
        "    key_points: list\n",
        "    tags: list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N8ZJc2H4QgaB"
      },
      "outputs": [],
      "source": [
        "#api call\n",
        "openai_api_key = getpass(\"Enter your OpenAI API key: \")\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "#def openAI\n",
        "def process_with_openai(raw_text):\n",
        "    prompt = f\"\"\"\n",
        "    You are a data processing assistant. Given the raw text, convert it into a JSON format with the following fields:\n",
        "    - \"title\": A brief title summarizing the text.\n",
        "    - \"summary\": A concise summary.\n",
        "    - \"key_points\": A list of key points.\n",
        "    - \"tags\": Relevant tags.\n",
        "\n",
        "    Text: \"{raw_text}\"\n",
        "\n",
        "    JSON:\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=200,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        output = response['choices'][0]['message']['content'].strip()\n",
        "        return ProcessedData.parse_raw(output)\n",
        "    except ValidationError as e:\n",
        "        print(\"Validation Error:\", e)\n",
        "        return None\n",
        "    except openai.error.OpenAIError as e:\n",
        "        print(\"API Error:\", e)\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9DwQQqOWzii"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ucy22LU-QjkD",
        "outputId": "7a51b7ac-ad36-4482-9e2e-0c07a486ba9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing with OpenAI API...\n",
            "\n",
            "OpenAI Output:\n",
            "{\n",
            "    \"title\": \"Benefits of Cloud Computing\",\n",
            "    \"summary\": \"Cloud computing offers flexible resources over the internet for on-demand access to servers, storage, and applications. Companies use it for scalability and cost efficiency.\",\n",
            "    \"key_points\": [\n",
            "        \"Flexible resources over the internet\",\n",
            "        \"On-demand access to servers, storage, and applications\",\n",
            "        \"Scalability\",\n",
            "        \"Cost efficiency\"\n",
            "    ],\n",
            "    \"tags\": [\n",
            "        \"Cloud Computing\",\n",
            "        \"Scalability\",\n",
            "        \"Cost Efficiency\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "raw_text = \"\"\"\n",
        "Cloud computing provides flexible resources over the internet, enabling on-demand access to servers, storage, and applications.\n",
        "Companies adopt it for scalability and cost efficiency.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "print(\"Processing with OpenAI API...\")\n",
        "openai_output = process_with_openai(raw_text)\n",
        "if openai_output:\n",
        "    print(\"\\nOpenAI Output:\")\n",
        "    print(json.dumps(openai_output.dict(), indent=4))\n",
        "else:\n",
        "    print(\"Failed to process with OpenAI.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GknRrEotQmsM",
        "outputId": "b70e0178-1b17-472d-8c2f-c558e07b018d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Hugging Face token: ··········\n"
          ]
        }
      ],
      "source": [
        "#hf login with token\n",
        "hf_token = getpass(\"Enter your Hugging Face token: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atM_7c2U3C2d",
        "outputId": "55bf35be-60e5-4b62-e0d0-2b7808010198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Colab Access fine tune` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Colab Access fine tune`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI177YFX-djm",
        "outputId": "b7f1919e-1cae-45c8-c52a-080473d90f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-cased and revision 6ea8117 (https://huggingface.co/distilbert/distilbert-base-cased).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Your max_length is set to 100, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"title\": \"Cloud computing provides flexible resources over the internet, enabling on-demand access to servers, storage, and applications.\",\n",
            "    \"summary\": \"Companies adopt it for scalability and cost efficiency. Cloud computing provides flexible resources over the internet. It enables on-demand access to servers, storage, and applications.\",\n",
            "    \"key_points\": [\n",
            "        \"Companies adopt it for scalability and cost efficiency\",\n",
            "        \"Cloud computing provides flexible resources over the internet\",\n",
            "        \"It enables on-demand access to servers, storage, and applications.\"\n",
            "    ],\n",
            "    \"tags\": [\n",
            "        \"Companies\",\n",
            "        \"adopt\",\n",
            "        \"scalability\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from transformers import pipeline\n",
        "\n",
        "#load models\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "keyword_extractor = pipeline(\"feature-extraction\")  #this can be used for extracting features\n",
        "\n",
        "def local_model(text):\n",
        "\n",
        "    title = text.split('\\n')[0]\n",
        "\n",
        "    summary = summarizer(text, max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
        "\n",
        "    key_points = summary.split('. ')\n",
        "\n",
        "    tags = [word for word in summary.split() if len(word) > 3][:3]\n",
        "    structured_json = {\n",
        "        \"title\": title,\n",
        "        \"summary\": summary,\n",
        "        \"key_points\": key_points,\n",
        "        \"tags\": tags\n",
        "    }\n",
        "\n",
        "    return structured_json\n",
        "\n",
        "\n",
        "#input of raw data\n",
        "raw_text = \"\"\"Cloud computing provides flexible resources over the internet, enabling on-demand access to servers, storage, and applications.\n",
        "Companies adopt it for scalability and cost efficiency.\"\"\"\n",
        "\n",
        "structured_json = extract_title_and_summary(raw_text)\n",
        "print(json.dumps(structured_json, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te3P4yShQz97"
      },
      "source": [
        "# Comparision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWS7n22sQvwZ",
        "outputId": "daad1554-0d20-4e31-cb78-b3cfe0a637b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison:\n",
            "{\n",
            "    \"OpenAI Output\": {\n",
            "        \"title\": \"Benefits of Cloud Computing\",\n",
            "        \"summary\": \"Cloud computing offers flexible resources over the internet for on-demand access to servers, storage, and applications. Companies use it for scalability and cost efficiency.\",\n",
            "        \"key_points\": [\n",
            "            \"Flexible resources over the internet\",\n",
            "            \"On-demand access to servers, storage, and applications\",\n",
            "            \"Scalability\",\n",
            "            \"Cost efficiency\"\n",
            "        ],\n",
            "        \"tags\": [\n",
            "            \"Cloud Computing\",\n",
            "            \"Scalability\",\n",
            "            \"Cost Efficiency\"\n",
            "        ]\n",
            "    },\n",
            "    \"Local Model Output\": {\n",
            "        \"title\": \"Cloud computing provides flexible resources over the internet, enabling on-demand access to servers, storage, and applications.\",\n",
            "        \"summary\": \"Companies adopt it for scalability and cost efficiency. Cloud computing provides flexible resources over the internet. It enables on-demand access to servers, storage, and applications.\",\n",
            "        \"key_points\": [\n",
            "            \"Companies adopt it for scalability and cost efficiency\",\n",
            "            \"Cloud computing provides flexible resources over the internet\",\n",
            "            \"It enables on-demand access to servers, storage, and applications.\"\n",
            "        ],\n",
            "        \"tags\": [\n",
            "            \"Companies\",\n",
            "            \"adopt\",\n",
            "            \"scalability\"\n",
            "        ]\n",
            "    }\n",
            "}\n",
            "\n",
            "Comparison saved to comparison_output.json. You can download it.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "#comparing both results\n",
        "if openai_output and local_model:\n",
        "\n",
        "    local_model_output = local_model(raw_text)\n",
        "\n",
        "    comparison = {\n",
        "        \"OpenAI Output\": openai_output.dict(),\n",
        "        \"Local Model Output\": local_model_output\n",
        "    }\n",
        "\n",
        "\n",
        "    print(\"\\nComparison:\")\n",
        "    print(json.dumps(comparison, indent=4))\n",
        "\n",
        "\n",
        "    json_file_path = 'comparison_output.json'\n",
        "\n",
        "    with open(json_file_path, 'w') as json_file:\n",
        "        json.dump(comparison, json_file, indent=4)\n",
        "\n",
        "    print(f\"\\nComparison saved to {json_file_path}. You can download it.\")\n",
        "\n",
        "else:\n",
        "    print(\"Comparison not possible. One or both outputs are missing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89mG0kkvRUVj"
      },
      "source": [
        "# Save Result"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}